{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №7\n",
    "# Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача регрессии заключается в построении некоторой функции $y\\left(x_{1},x_{2},...,x_{d}\\right)$, которая наилучшим образом описывает данные из некоторой обучающей выборки $U$, в которой каждому вектору предикторов $x$ ставится в соответствие зависимая переменная $y$. Эта функция ищется в некотором конкретном классе функций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Понятие линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия (linear regression) — это метод восстановления зависимости одной (объясняемой, зависимой) переменной $y$ от другой или нескольких других переменных (факторов, независимых переменных) $\\mathbf{x}$ с линейной функцией зависимости от коэффициентов $\\mathbf{a}=\\left(a_{1},...,a_{m}\\right)^{T}$ вида: \n",
    "\n",
    "$y=f\\left(\\mathbf{x},\\mathbf{a}\\right)=\\sum_{k=1}^{m}a_{i}f_{i}\\left(\\mathbf{x}\\right),$\n",
    "\n",
    "где $\\mathbf{x}\\in\\mathbb{R}^{d}$, $\\mathbf{a}\\in\\mathbb{R}^{m}$, $f_{1}\\left(\\mathbf{x}\\right),...,f_{m}\\left(\\mathbf{x}\\right)$ – некоторые функции. \n",
    "\n",
    "Наиболее популярным вариантом линейной регрессии является предположение $f_{i}\\left(\\mathbf{x}\\right)\\equiv x_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1., 2., 3., 4., 5.])\n",
    "y = np.array([1., 3., 2., 3., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.axis([0, 6, 0, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = np.mean(x)\n",
    "y_mean = np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вычисления коэффициента $a$ прямой $y=a\\,x+b$ нужно вычислить  выборочную ковариацию переменных $x$ и $y$ и выборочную дисперсию переменной (признака) $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0.0\n",
    "d = 0.0\n",
    "for x_i, y_i in zip(x, y):\n",
    "    num += (x_i - x_mean) * (y_i - y_mean)\n",
    "    d += (x_i - x_mean) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = num/d\n",
    "b = y_mean - a * x_mean\n",
    "y_hat = a * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_hat, color='r')\n",
    "plt.axis([0, 6, 0, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построенная таким образом функция позволяет прогнозировать значение $y$ по $x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = 6\n",
    "y_predict = a * x_predict + b\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим программный код в следующий класс `SimpleLinearRegression1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression1:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.a_ = None\n",
    "        self.b_ = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        assert x_train.ndim == 1, \\\n",
    "            \"Simple Linear Regressor can only solve single feature training data.\"\n",
    "        assert len(x_train) == len(y_train), \\\n",
    "            \"the size of x_train must be equal to the size of y_train\"\n",
    "\n",
    "        x_mean = np.mean(x_train)\n",
    "        y_mean = np.mean(y_train)\n",
    "\n",
    "        num = 0.0\n",
    "        d = 0.0\n",
    "        for x, y in zip(x_train, y_train):\n",
    "            num += (x - x_mean) * (y - y_mean)\n",
    "            d += (x - x_mean) ** 2\n",
    "\n",
    "        self.a_ = num / d\n",
    "        self.b_ = y_mean - self.a_ * x_mean\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_predict):\n",
    "        assert x_predict.ndim == 1, \\\n",
    "            \"Simple Linear Regressor can only solve single feature training data.\"\n",
    "        assert self.a_ is not None and self.b_ is not None, \\\n",
    "            \"must fit before predict!\"\n",
    "\n",
    "        return np.array([self._predict(x) for x in x_predict])\n",
    "\n",
    "    def _predict(self, x_single):\n",
    "        return self.a_ * x_single + self.b_\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"SimpleLinearRegression1()\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно создавать объекты этого класса при помощи конструктора и применять к объектам методы класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = SimpleLinearRegression1()\n",
    "reg1.fit(x, y)\n",
    "reg1.predict(np.array([x_predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1.a_, reg1.b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat1 = reg1.predict(x)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_hat1, color='r')\n",
    "plt.axis([0, 6, 0, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим также альтернативную реализацию регрессии в классе `SimpleLinearRegression2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improved, the for loop is realized by vectorization to increase efficiency\n",
    "class SimpleLinearRegression2:\n",
    "    def __init__(self):\n",
    "        self.a_=None\n",
    "        self.b_=None\n",
    " \n",
    "    def fit(self,x_train,y_train):\n",
    "        x_mean = np.mean(x_train)\n",
    "        y_mean = np.mean(y_train)\n",
    "        # up = np.dot((x_train-x_mean),(y_train-y_mean))\n",
    "        # down =np.dot((x_train-x_mean),(x_train-x_mean))\n",
    "        up = np.sum((x_train - x_mean)*(y_train - y_mean))\n",
    "        down = np.sum((x_train - x_mean)*(x_train - x_mean))\n",
    "        self.a_ = up / down\n",
    "        self.b_ = y_mean - self.a_ * x_mean\n",
    "        return self\n",
    " \n",
    "    def _predict(self,x_single):\n",
    "        return x_single*self.a_+self.b_\n",
    "    def predict(self,x_predict):\n",
    "        return np.array([self._predict(x) for x in x_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2 = SimpleLinearRegression2()\n",
    "reg2.fit(x, y)\n",
    "reg2.predict(np.array([x_predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2.a_, reg2.b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1000000\n",
    "big_x = np.random.random(size=m)\n",
    "big_y = big_x * 2 + 3 + np.random.normal(size=m)\n",
    "%timeit reg1.fit(big_x, big_y)\n",
    "%timeit reg2.fit(big_x, big_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1.a_, reg1.b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg2.a_, reg2.b_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston.data[:,5] \n",
    "y = boston.target\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим набор от точек, расположенных вдоль верхней границы графика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[y < 50.0]\n",
    "y = y[y < 50.0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем пользовать следующей версией функции `train_test_split`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_ratio=0.2, seed=None):\n",
    "    \n",
    "    assert X.shape[0] == y.shape[0], \\\n",
    "        \"the size of X must be equal to the size of y\"\n",
    "    assert 0.0 <= test_ratio <= 1.0, \\\n",
    "        \"test_ration must be valid\"\n",
    "\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    shuffled_indexes = np.random.permutation(len(X))\n",
    "\n",
    "    test_size = int(len(X) * test_ratio)\n",
    "    test_indexes = shuffled_indexes[:test_size]\n",
    "    train_indexes = shuffled_indexes[test_size:]\n",
    "\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, seed=666)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать новую версию класса для регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.a_ = None\n",
    "        self.b_ = None\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        assert x_train.ndim == 1, \\\n",
    "            \"Simple Linear Regressor can only solve single feature training data.\"\n",
    "        assert len(x_train) == len(y_train), \\\n",
    "            \"the size of x_train must be equal to the size of y_train\"\n",
    "\n",
    "        x_mean = np.mean(x_train)\n",
    "        y_mean = np.mean(y_train)\n",
    "\n",
    "        self.a_ = (x_train - x_mean).dot(y_train - y_mean) / (x_train - x_mean).dot(x_train - x_mean)\n",
    "        self.b_ = y_mean - self.a_ * x_mean\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, x_predict):\n",
    "        assert x_predict.ndim == 1, \\\n",
    "            \"Simple Linear Regressor can only solve single feature training data.\"\n",
    "        assert self.a_ is not None and self.b_ is not None, \\\n",
    "            \"must fit before predict!\"\n",
    "\n",
    "        return np.array([self._predict(x) for x in x_predict])\n",
    "\n",
    "    def _predict(self, x_single):\n",
    "        return self.a_ * x_single + self.b_\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"SimpleLinearRegression()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = SimpleLinearRegression()\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.a_, reg.b_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим на графике точки обучающего набора и линию регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x_train, reg.predict(x_train), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь добавим также точки тестового набора другим цветом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_train, y_train)\n",
    "plt.scatter(x_test, y_test, color=\"c\")\n",
    "plt.plot(x_train, reg.predict(x_train), color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Среднее квадратичное отклонение MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средняя квадратичная ошибка (Mean Squared Error, MSE)\n",
    "применяется в ситуациях, когда нам надо подчеркнуть большие ошибки и выбрать модель, которая дает меньше больших ошибок прогноза. \n",
    "\n",
    "$MSE=\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$\n",
    "\n",
    "Грубые ошибки становятся заметнее за счет того, что ошибку прогноза мы возводим в квадрат. И про модель, которая дает нам меньшее значение среднеквадратической ошибки, можно сказать, что что у этой модели меньше грубых ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test = np.sum((y_predict - y_test)**2) / len(y_test)\n",
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корень из средней квадратичной ошибки RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корень из средней квадратичной ошибки (Root Mean Squared Error, RMSE)\n",
    "получается из MSE путем извлечения корня.\n",
    "\n",
    "$RMSE=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}$\n",
    "\n",
    "Каждое отклонение возводится в квадрат, любое небольшое отклонение может значительно повлиять на показатель ошибки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "rmse_test = sqrt(mse_test)\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cредняя абсолютная ошибка MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cредняя абсолютная ошибка (Mean Absolute Error, MAE) не так сильно  штрафует за большие отклонения по сравнению со среднеквадратичным, и поэтому менее чувствительна к выбросам.\n",
    "\n",
    "$MAE=\\frac{1}{n}\\sum_{i=1}^{n}\\left|y_{i}-\\hat{y}_{i}\\right|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test = np.sum(np.absolute(y_predict - y_test))/len(y_test)\n",
    "mae_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатели MSE и MAE определены в scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коэффициент детерминации $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент детерминации $R^2$ измеряет долю дисперсии, объясненную моделью, в общей дисперсии целевой переменной. \n",
    "\n",
    "$R^{2}=1-\\frac{Q}{S_{0}}, Q=\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}, S_{0}=\\sum_{i=1}^{n}\\left(y-\\bar{y}\\right)^{2}$,\n",
    "\n",
    "где $\\bar{y}$ – это выборочное среднее зависимой переменной $y$. Фактически, данная мера качества — это нормированная среднеквадратичная ошибка. Если она близка к единице, то модель хорошо объясняет данные, если же она близка к нулю, то прогнозы сопоставимы по качеству с константным предсказанием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - mean_squared_error(y_test, y_predict)/np.var(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия в scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для использования линейной регрессии в scikit-learn можно воспользоваться классом `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y < 50.0]\n",
    "y = y[y < 50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, seed=666)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, np.newaxis]\n",
    "X_test = X_test[:, np.newaxis]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `score()` возвращает коэффициент детерминации $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подбора наилучших параметров регрессии можно использовать класс `GridSearchCV` из библиотеки `scikit-learn`. `GridSearchCV` находит наилучшие параметры путем обычного перебора: он создает модель для каждой возможной комбинации параметров, поэтому такой подход может быть весьма затратным по ресурсам.\n",
    "\n",
    "Рассмотрим в качестве примера регрессор на основе метода ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "standardScaler.fit(X_train, y_train)\n",
    "X_train_standard = standardScaler.transform(X_train)\n",
    "X_test_standard = standardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С параметрами регрессора по умолчанию получаем следующий результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_reg = KNeighborsRegressor()\n",
    "knn_reg.fit(X_train_standard, y_train)\n",
    "knn_reg.score(X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся `GridSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"weights\": [\"uniform\"],\n",
    "        \"n_neighbors\": [i for i in range(1, 11)]\n",
    "    },\n",
    "    {\n",
    "        \"weights\": [\"distance\"],\n",
    "        \"n_neighbors\": [i for i in range(1, 11)],\n",
    "        \"p\": [i for i in range(1,6)]\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_reg = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn_reg, param_grid, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_standard, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры лучшего регрессора находятся в свойстве `best_params_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Средний показатель качества лучшего регрессора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На нашем тестовом наборе лучший регрессор имеет показатель качества: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.score(X_test_standard, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полиномиальная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полиномиальная регрессия может использоваться для регрессии нелинейных данных. В полиномиальной регрессии проводится кривая линия, соответствующая полиному степени больше 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-3, 3, size=100)\n",
    "X = x.reshape(-1, 1)\n",
    "y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "y_predict = lin_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_predict, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.hstack([X, X**2])\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit(X2, y)\n",
    "y_predict2 = lin_reg2.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x), y_predict2[np.argsort(x)], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg2.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Конвейер (Pipeline) в задаче регрессии "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-3, 3, size=100)\n",
    "X = x.reshape(-1, 1)\n",
    "y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit(X)\n",
    "X2 = poly.transform(X)\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg2 = LinearRegression()\n",
    "lin_reg2.fit(X2, y)\n",
    "y_predict2 = lin_reg2.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x), y_predict2[np.argsort(x)], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg2.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс `PolynomialFeatures` позволяет строить наборы данных, содержащий полиномиальные зависимости от исходных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(1, 11).reshape(-1, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "poly.fit(X)\n",
    "X2 = poly.transform(X)\n",
    "X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение конвейера (Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.uniform(-3, 3, size=100)\n",
    "X = x.reshape(-1, 1)\n",
    "y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, 100)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "poly_reg = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=2)),\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "    (\"lin_reg\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg.fit(X, y)\n",
    "y_predict = poly_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переобучение и недообучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переобучение (overfitting) — это ситуация, когда алгоритм обучения вырабатывает предсказания, которые слишком близко или точно соответствуют конкретному набору данных и не подходят для применения к другим данным или будущим наблюдениям.\n",
    "\n",
    "Недообучение (underfitting) — это ситуация, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно сложных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)\n",
    "x = np.random.uniform(-3.0, 3.0, size=100)\n",
    "X = x.reshape(-1, 1)\n",
    "y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lin_reg.predict(X)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x), y_predict[np.argsort(x)], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_predict = lin_reg.predict(X)\n",
    "mean_squared_error(y, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def PolynomialRegression(degree):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"lin_reg\", LinearRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2_reg = PolynomialRegression(degree=2)\n",
    "poly2_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_predict = poly2_reg.predict(X)\n",
    "mean_squared_error(y, y2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x), y2_predict[np.argsort(x)], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly10_reg = PolynomialRegression(degree=10)\n",
    "poly10_reg.fit(X, y)\n",
    "\n",
    "y10_predict = poly10_reg.predict(X)\n",
    "mean_squared_error(y, y10_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x), y10_predict[np.argsort(x)], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly100_reg = PolynomialRegression(degree=100)\n",
    "poly100_reg.fit(X, y)\n",
    "\n",
    "y100_predict = poly100_reg.predict(X)\n",
    "mean_squared_error(y, y100_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(np.sort(x), y100_predict[np.argsort(x)], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.linspace(-3, 3, 100).reshape(100, 1)\n",
    "y_plot = poly100_reg.predict(X_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(X_plot[:,0], y_plot, color='r')\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающая и тестовые выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(X_train, y_train)\n",
    "y_predict = lin_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2_reg.fit(X_train, y_train)\n",
    "y2_predict = poly2_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly10_reg.fit(X_train, y_train)\n",
    "y10_predict = poly10_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y10_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly100_reg.fit(X_train, y_train)\n",
    "y100_predict = poly100_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y100_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кривые обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кривые обучения — это графическое представление зависимости меры (показателя) качества обучения (по вертикальной оси) от определенного показателя модели обучения (по горизонтальной оси). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)\n",
    "x = np.random.uniform(-3.0, 3.0, size=100)\n",
    "X = x.reshape(-1, 1)\n",
    "y = 0.5 * x**2 + x + 2 + np.random.normal(0, 1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем визуализировать в качестве качества модели показатели `RMSE` для части обучающей выборки и тестовой выборки в зависимости от количества точек в обучающей выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "for i in range(1, 76):\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train[:i], y_train[:i])\n",
    "    \n",
    "    y_train_predict = lin_reg.predict(X_train[:i])\n",
    "    train_score.append(mean_squared_error(y_train[:i], y_train_predict))\n",
    "    \n",
    "    y_test_predict = lin_reg.predict(X_test)\n",
    "    test_score.append(mean_squared_error(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1, 76)], np.sqrt(train_score), label=\"train\")\n",
    "plt.plot([i for i in range(1, 76)], np.sqrt(test_score), label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(algo, X_train, X_test, y_train, y_test):\n",
    "    train_score = []\n",
    "    test_score = []\n",
    "    for i in range(1, len(X_train)+1):\n",
    "        algo.fit(X_train[:i], y_train[:i])\n",
    "    \n",
    "        y_train_predict = algo.predict(X_train[:i])\n",
    "        train_score.append(mean_squared_error(y_train[:i], y_train_predict))\n",
    "    \n",
    "        y_test_predict = algo.predict(X_test)\n",
    "        test_score.append(mean_squared_error(y_test, y_test_predict))\n",
    "        \n",
    "    plt.plot([i for i in range(1, len(X_train)+1)], \n",
    "                               np.sqrt(train_score), label=\"train\")\n",
    "    plt.plot([i for i in range(1, len(X_train)+1)], \n",
    "                               np.sqrt(test_score), label=\"test\")\n",
    "    plt.legend()\n",
    "    plt.axis([0, len(X_train)+1, 0, 4]) # np.sqrt(test_score).max()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(LinearRegression(), X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def PolynomialRegression(degree):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"lin_reg\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "poly2_reg = PolynomialRegression(degree=2)\n",
    "plot_learning_curve(poly2_reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly20_reg = PolynomialRegression(degree=20)\n",
    "plot_learning_curve(poly20_reg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация линейной регрессии\n",
    "\n",
    "#### Переобучение линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x = np.random.uniform(-3.0, 3.0, size=100)\n",
    "X = x.reshape(-1, 1)\n",
    "y = 0.5 * x + 3 + np.random.normal(0, 1, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def PolynomialRegression(degree):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"lin_reg\", LinearRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(666)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "poly_reg = PolynomialRegression(degree=20)\n",
    "poly_reg.fit(X_train, y_train)\n",
    "\n",
    "y_poly_predict = poly_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y_poly_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.linspace(-3, 3, 100).reshape(100, 1)\n",
    "y_plot = poly_reg.predict(X_plot)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(X_plot[:,0], y_plot, color='r')\n",
    "plt.axis([-3, 3, 0, 6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model):\n",
    "    X_plot = np.linspace(-3, 3, 100).reshape(100, 1)\n",
    "    y_plot = model.predict(X_plot)\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "    plt.plot(X_plot[:,0], y_plot, color='r')\n",
    "    plt.axis([-3, 3, 0, 6])\n",
    "    plt.show()\n",
    "\n",
    "plot_model(poly_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Гребневая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гребневая регрессия (ridge regression) – это регрессия, в которой используется функция потерь\n",
    "\n",
    "$Q\\left(\\beta\\right)=\\sum_{i=1}^{n}\\mathcal{L}\\left(y_{i},g\\left(x_{i},\\beta\\right)\\right)+\\alpha\\sum_{j=1}^{d}\\beta_{j}^{2}$\n",
    "\n",
    "Использование гребневой регрессии позволяет избежать переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def RidgeRegression(degree, alpha):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"ridge_reg\", Ridge(alpha=alpha))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge1_reg = RidgeRegression(20, 0.0001)\n",
    "ridge1_reg.fit(X_train, y_train)\n",
    "\n",
    "y1_predict = ridge1_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(ridge1_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2_reg = RidgeRegression(20, 1)\n",
    "ridge2_reg.fit(X_train, y_train)\n",
    "\n",
    "y2_predict = ridge2_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(ridge2_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge3_reg = RidgeRegression(20, 100)\n",
    "ridge3_reg.fit(X_train, y_train)\n",
    "\n",
    "y3_predict = ridge3_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y3_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(ridge3_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge4_reg = RidgeRegression(20, 10000000)\n",
    "ridge4_reg.fit(X_train, y_train)\n",
    "\n",
    "y4_predict = ridge4_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y4_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(ridge4_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Регрессия лассо (LASSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В регрессии лассо (LASSO, Least Absolute Shrinkage and Selection Operator) используется регуляризация через манхэттенское расстояние:\n",
    "\n",
    "$Q\\left(\\beta\\right)=\\sum_{i=1}^{n}\\mathcal{L}\\left(y_{i},g\\left(x_{i},\\beta\\right)\\right)+\\alpha\\sum_{j=1}^{d}\\left|\\beta_{j}\\right|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def LassoRegression(degree, alpha):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"lasso_reg\", Lasso(alpha=alpha))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso1_reg = LassoRegression(20, 0.01)\n",
    "lasso1_reg.fit(X_train, y_train)\n",
    "\n",
    "y1_predict = lasso1_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lasso1_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2_reg = LassoRegression(20, 0.1)\n",
    "lasso2_reg.fit(X_train, y_train)\n",
    "\n",
    "y2_predict = lasso2_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lasso2_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso3_reg = LassoRegression(20, 1)\n",
    "lasso3_reg.fit(X_train, y_train)\n",
    "\n",
    "y3_predict = lasso3_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y3_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(lasso3_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Регрессия эластичная сеть (elastic net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В регрессии эластичная сеть (elastic net) используется регуляризация:\n",
    "\n",
    "$Q\\left(\\beta\\right)=\\sum_{i=1}^{n}\\mathcal{L}\\left(y_{i},g\\left(x_{i},\\beta\\right)\\right)+\\alpha_{1}\\sum_{j=1}^{d}\\left|\\beta_{j}\\right|+\\alpha_{2}\\sum_{j=1}^{d}\\beta_{j}^{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "def ElNetRegression(degree, alpha):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"elnet_reg\", ElasticNet(alpha=alpha))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В конструкторе класса `ElasticNet` также имеется параметр `l1_ratio`, по умолчанию равный 0.5. Если `l1_ratio = 0` то штраф как в гребневой регрессии ($L_2$). Если `l1_ratio = 1`, то штраф как в регрессии лассо ($L_1$). Если `0 < l1_ratio < 1`, то штраф представляет собой комбинацию ($L_1$) и ($L_2$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elnet1_reg = ElNetRegression(20, 0.01)\n",
    "elnet1_reg.fit(X_train, y_train)\n",
    "\n",
    "y1_predict = elnet1_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(elnet1_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Регрессия при помощи деревьев решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деревья решений могут быть использованы не только для решения задачи классификации, но и для решения задачи регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def TreeRegression(max_leaf_nodes=None):\n",
    "    return Pipeline([\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"tree_reg\", DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1_reg = TreeRegression(4)\n",
    "tree1_reg.fit(X_train, y_train)\n",
    "\n",
    "y1_predict = tree1_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tree1_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Регрессия при помощи SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи регрессии может также быть использован метод опорных векторов (Support Vector Machines, SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def SVMRegression(degree):\n",
    "    return Pipeline([\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "        (\"svm_reg\", SVR(kernel='poly',degree=degree))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm1_reg = SVMRegression(5)\n",
    "svm1_reg.fit(X_train, y_train)\n",
    "\n",
    "y1_predict = svm1_reg.predict(X_test)\n",
    "mean_squared_error(y_test, y1_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(svm1_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор признаков при помощи линейной регрессии\n",
    "\n",
    "Линейная регрессия, а также гребневая регрессия и регрессия лассо, могут быть использованы для отбора числовых признаков следующим образом: большую важность (значимость) будут иметь те признаки, для которых коэффициенты регрессии по абсолютной величине принимают большие значения. Признаки с коэффициентами регрессии, близкими к нулю, мало влияют на прогнозируемые значения отклика."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбросы\n",
    "\n",
    "Выбросами (outliers) называются записи (точки) набора данных с характеристиками, которые существенно отличаются от характеристик остальных записей набора данных. \n",
    "\n",
    "Чтобы убрать выбросы, можно посчитать стандартизованную оценку (Z-score) для каждого признака и убрать записи, содержащие атрибуты с ненормально высоким или низким Z-score, превышающим по абсолютной величине пороговое значение $\\lambda$ (например, $Z>\\lambda$ или $Z<-\\lambda$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Z = (X_train-X_train.mean())/X_train.std()\n",
    "X_train_Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 1.\n",
    "X_train_new = X_train_Z[(X_train_Z >= -lam) & (X_train_Z <= lam)].reshape(-1,1)\n",
    "X_train_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точки набора данных могут помечаться как выбросы некоторыми алгоритмами кластеризации. \n",
    "\n",
    "В алгоритме DBSCAN одиноко расположенные точки помечаются как выбросы (шум)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "model = DBSCAN(eps=0.20, min_samples=5)\n",
    "yhat = model.fit_predict(X_train)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Метки кластеров:\", set(model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Доля некластеризованных точек (выбросов):\", list(model.labels_).count(-1) / len(list(model.labels_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также точки набора данных помечаются как шум (выбросы) в алгоритме OPTICS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание на лабораторную работу №7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для закрепленного за Вами варианта лабораторной работы:\n",
    "\n",
    "1.\tСчитайте заданный набор данных из репозитария UCI, включая указанный в индивидуальном задании столбец с метками классов и столбец с откликом (зависимой переменной).\n",
    "\n",
    "2.\tПреобразуйте в числовые признаки неправильно распознанные признаки с числовыми значениями. Если в столбцах с метками классов и откликом имеются пропущенные значения, то удалите записи с пропущенными значениями. Оставьте в наборе данных только числовые признаки. \n",
    "\n",
    "3.\tЕсли в наборе данных остались пропущенные значения, то замените пропущенные значения, используя метод, указанный в индивидуальном задании. Если пропущенные значения в наборе данных отсутствуют, то определите и удалите точки с выбросами в соответствии с методом, указанным в индивидуальном задании. Выберите параметры методов таким образом, чтобы выбросы составляли не менее 5% всех точек набора данных. \n",
    "\n",
    "4.\tМасштабируйте признаки набора данных на интервал [0, 1]. Используя метод снижения размерности данных, указанный в индивидуальном задании, оставьте в наборе данных три признака (кроме метки класса и откликов), принимающих более 50 различных значений. \n",
    "\n",
    "5.\tВизуализируйте набор данных в виде точек в трехмерном пространстве, отображая точки разных классов разными цветами. В качестве подписей осей используйте названия признаков. В подписи рисунка укажите название набора данных. Создайте легенду набора данных.\n",
    "\n",
    "6.\tРазбейте набор данных на обучающую и тестовую выборки. Постройте регрессоры на базе моделей регрессии, указанных в индивидуальном задании, для каждого из трех признаков. Определите оптимальные параметры регрессоров при помощи GridSearchCV.\n",
    "\n",
    "7.\tДля каждого из трех признаков визуализируйте на плоскости набор данных одним цветом и линии регрессии для регрессоров с оптимальными параметрами, определенными в п. 6 (всего три рисунка). Регрессоры, имеющие максимальное значение показателя качества регрессии, указанного в индивидуальном задании, выделите красным цветом. В качестве подписи оси X используйте название признака, в качестве подписи оси Y – название столбца с откликами. Создайте легенду для линий регрессии.\n",
    "\n",
    "8.\tПостройте на одном рисунке кривые обучения (зависимость показателя качества регрессии, указанного в индивидуальном задании, от количества точек в обучающей выборке) для трех лучших регрессоров для каждого из трех признаков по показателю качества, указанному в индивидуальном задании. Кривые для регрессора с максимальным показателем качества визуализируйте красным цветом (кривую для обучающей выборки сплошной линией, кривую для тестовой выборки линией из точек). Подпишите корректно оси и создайте легенду для кривых обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
