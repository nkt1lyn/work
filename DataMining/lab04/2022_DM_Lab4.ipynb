{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №4\n",
    "# Задача класссификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть имеется множество объектов, характеризующихся признаками и разделённых некоторым образом на классы.\n",
    "\n",
    "Задача классификации — это задача построения алгоритма (функции), способного \n",
    "классифицировать произвольный объект из исходного пространства признаков, т.е. определять метку класса для этого объекта.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка наборов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые наиболее часто используемые в учебных и исследовательских целях наборы данных можно загрузить напрямую из бибиотеки scikit-learn. Это относится к таким наборам, как\n",
    "\n",
    "* boston house-prices dataset (regression)\n",
    "* iris dataset (classification)  \n",
    "* diabetes dataset (regression)  \n",
    "* digits dataset (classification)  \n",
    "* physical excercise linnerud dataset  \n",
    "* wine dataset (classification)  \n",
    "* breast cancer wisconsin dataset (classification)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, для загрузки набора \"Ирисы\" можно использовать код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных загружается в словарь специального вида со следующими ключами: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Названия признаков и меток классов находятся в элементах `feature_names` и `target_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Признаки: \", iris['feature_names'] )\n",
    "print( \"Метки: \", iris.target_names )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения признаков и меток хранятся в элементах `data` и `target` как массивы `ndarray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.data[0:5])\n",
    "print(iris.target[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вызвать метод `load_iris()` с ключом `as_frame=True`, то набор данных будет доступен как объект `DataFrame`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris2 = datasets.load_iris(as_frame=True)\n",
    "type(iris2.frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг наборов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во многих алгоритмах классификации содержатся допущения относительно классифицируемых данных, поэтому в ряде случаев может потребоваться предварительная подготовка (препроцессинг) данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Масштабирование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если данные содержат признаки разного масштаба, то многие алгоритмы классификации работают лучше, когда признаки имеют одинаковый масштаб. В частности, это полезно для алгоритмов, использующих меры расстояния, такие как метод k-ближайших соседей. \n",
    "\n",
    "Создадим случайный набор точек, преобразуем целочисленный массив `X` к типу `float`, масштабируем его на интервал `[0, 1]` и визуализируем на плоскости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.random.randint(0, 100, (50, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# масштабирование на [0,1]\n",
    "X[:,0] = (X[:,0] - np.min(X[:,0])) / (np.max(X[:,0]) - np.min(X[:,0]))\n",
    "X[:,1] = (X[:,1] - np.min(X[:,1])) / (np.max(X[:,1]) - np.min(X[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.axis('square')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно масштабировать данные, используя класс `MinMaxScaler` из scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "X = iris.data\n",
    "scaler = MinMaxScaler(feature_range=(1, 5)) # значения признаков от 1 до 5\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стандартизация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизация - это метод преобразования признаков к виду, когда они имеют среднее значение 0 и стандартное отклонение 1. Этот способ подходит, в частности, для методов машинного обучения, предполагающих нормальное распределение входных данных. \n",
    "\n",
    "Создадим случайный набор точек, преобразуем целочисленный массив `X` к типу `float`, стандартизуем его и визуализируем на плоскости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 100, (50, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стандартизация\n",
    "X[:,0] = (X[:,0] - np.mean(X[:,0])) / np.std(X[:,0])\n",
    "X[:,1] = (X[:,1] - np.mean(X[:,1])) / np.std(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.axis('Equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X[:,0]), np.std(X[:,0]), np.mean(X[:,1]), np.std(X[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор данных можно стандартизовать при помощи класса `StandardScaler` из scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = iris.data\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормировка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормировка - это изменение масштаба каждой строки (записи) до единичной длины. Метод полезен для разреженных наборов данных (со многими нулями) при использовании\n",
    "алгоритмов, использующих расстояние (например, метод k-ближайших соседей). В качестве нормы можно использовать ‘l1’, ‘l2’ или ‘max’ (по умолчанию ‘l2’). \n",
    "Можно нормализовать данные с помощью класса `Normalizer` из scikit-learn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "X = iris.data\n",
    "scaler = Normalizer(norm='max').fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучающая и контрольная (тестовая) выборки\n",
    "\n",
    "Для оценки качества обученной модели классификации используют разбиение на обучающую (training) и тестовую (test) выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indexes = np.random.permutation(len(X))\n",
    "shuffled_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "test_size = int(len(X) * test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indexes = shuffled_indexes[:test_size]\n",
    "train_indexes = shuffled_indexes[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[train_indexes]\n",
    "y_train = y[train_indexes]\n",
    "\n",
    "X_test = X[test_indexes]\n",
    "y_test = y[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим использованный выше код в одну функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(X, y, test_ratio=0.2, seed=None):\n",
    "    \"\"\"returns X_train, X_test, y_train, y_test\"\"\"\n",
    "    assert X.shape[0] == y.shape[0], \\\n",
    "        \"the size of X must be equal to the size of y\"\n",
    "    assert 0.0 <= test_ratio <= 1.0, \\\n",
    "        \"test_ration must be valid\"\n",
    "\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    shuffled_indexes = np.random.permutation(len(X))\n",
    "\n",
    "    test_size = int(len(X) * test_ratio)\n",
    "    test_indexes = shuffled_indexes[:test_size]\n",
    "    train_indexes = shuffled_indexes[test_size:]\n",
    "\n",
    "    X_train = X[train_indexes]\n",
    "    y_train = y[train_indexes]\n",
    "\n",
    "    X_test = X[test_indexes]\n",
    "    y_test = y[test_indexes]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = my_train_test_split(X, y)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучающую и тестовую выборки с аналогичным интерфейсом реализовано в `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация методом K ближайших соседей\n",
    "\n",
    "В методе ближайших соседей точка классифицируется согласно классам ее ближайших соседей.\n",
    "\n",
    "Для иллюстрации метода рассмотрим следующий набор из 10 точек на плоскости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_X = [[3.393533211, 2.331273381],\n",
    "              [3.110073483, 1.781539638],\n",
    "              [2.280362439, 2.866990263],\n",
    "              [1.343808831, 3.368360954],\n",
    "              [3.582294042, 4.679179110],\n",
    "              [7.423436942, 4.696522875],\n",
    "              [5.745051997, 3.533989803],\n",
    "              [9.172168622, 2.511101045],\n",
    "              [7.792783481, 3.424088941],\n",
    "              [7.939820817, 0.791637231]\n",
    "             ]\n",
    "raw_data_y = [0, 0, 0, 0, 1, 1, 1, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(raw_data_X)\n",
    "y_train = np.array(raw_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[y_train==0,0], X_train[y_train==0,1], color='r')\n",
    "plt.scatter(X_train[y_train==1,0], X_train[y_train==1,1], color='g')\n",
    "plt.scatter(X_train[y_train==2,0], X_train[y_train==2,1], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем классифицировать по ближайщим соседям следующую точку `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([6.5, 3.])\n",
    "\n",
    "plt.scatter(X_train[y_train==0,0], X_train[y_train==0,1], color='r')\n",
    "plt.scatter(X_train[y_train==1,0], X_train[y_train==1,1], color='g')\n",
    "plt.scatter(X_train[y_train==2,0], X_train[y_train==2,1], color='b')\n",
    "plt.scatter(x[0], x[1], color='y', edgecolor='k', s=200)\n",
    "for idx in range(len(y_train)):\n",
    "    plt.text(X_train[idx,0]+0.1, X_train[idx,1], idx, fontsize=12, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве расстояния будем использовать евклидово расстояние на плоскости:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "\n",
    "for x_train in X_train:\n",
    "    d = np.sqrt(np.sum((x_train - x)**2))\n",
    "    distances.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [np.sqrt(np.sum((x_train - x)**2)) for x_train in X_train] # list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(distances) # индексы отсортированного списка (по возрастанию)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем выбирать класс точки `x` по `k` ближайщим соседям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest = np.argsort(distances)\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topK_y = [y_train[neighbor] for neighbor in nearest[:k]]\n",
    "topK_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "votes = Counter(topK_y)\n",
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = votes.most_common(1)[0][0]\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим программный код, использованный выше в одну функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from collections import Counter\n",
    "\n",
    "\n",
    "def kNN_classify(k, X_train, y_train, x):\n",
    "\n",
    "    assert 1 <= k <= X_train.shape[0], \"k must be valid\"\n",
    "    assert X_train.shape[0] == y_train.shape[0], \\\n",
    "        \"the size of X_train must equal to the size of y_train\"\n",
    "    assert X_train.shape[1] == x.shape[0], \\\n",
    "        \"the feature number of x must be equal to X_train\"\n",
    "\n",
    "    distances = [np.sqrt(np.sum((x_train - x)**2)) for x_train in X_train]\n",
    "    nearest = np.argsort(distances)\n",
    "\n",
    "    topK_y = [y_train[i] for i in nearest[:k]]\n",
    "    votes = Counter(topK_y)\n",
    "\n",
    "    return votes.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_classify(k, X_train, y_train, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичные результаты дает классификатор метода ближайших соседей из библиотеки scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kNN_clf = KNeighborsClassifier(n_neighbors=5) # создаем классификатор\n",
    "kNN_clf.fit(X_train, y_train)                 # обучаем классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификации точки `x` необходимо преобразование размеров (из вектора в матрицу):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из размерностей `reshape` может быть указана как -1, тогда значение этой размерности выводится из длины массива и других размерностей.\n",
    "\n",
    "Прогнозируем класс точки `x` при помощи "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kNN_clf.predict(x.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = kNN_clf.predict(x.reshape(1,-1))[0]\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем для точки `x` ту же метку класса `2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация набора данных digits\n",
    "\n",
    "Набор данных `digits` представляет собой изображения цифр от 0 до 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метки классов представляют собой цифры от 0 до 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А данные представляют собой изображения цифр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_digit = X[666]\n",
    "a_digit_image = a_digit.reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a_digit_image, cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим и обучим классификатор метода ближайщих соседей на обучающей выборке из набора `digits`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3) # по трем ближайшим соседям\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним прогнозирование меток классов (цифр):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество прогноза при помощи показателя \"доля верных ответов\" (accuracy) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_pred == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_predict):\n",
    "    '''input: y_true, y_predict\n",
    "       returns accuracy'''\n",
    "    assert y_true.shape[0] == y_predict.shape[0], \\\n",
    "        \"the size of y_true must be equal to the size of y_predict\"\n",
    "\n",
    "    return sum(y_true == y_predict) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также качество классификации можно оценить при помощи матрицы ошибок (по строкам истинные классы, по столбцам предсказанные классы), отчета о классификации, показателя доли ошибок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "conf_mat=confusion_matrix(y_test,y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Доля ошибок неправильной классификации:\",round(np.mean(y_pred!=y_test),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выбор оптимальных параметров классификатора\n",
    "\n",
    "При использовании классификаторов с параметрами возникает вопрос выбора оптимальных параметров классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "best_score = 0.0\n",
    "best_k = -1\n",
    "for k in range(1, 11):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    score = knn_clf.score(X_test, y_test)\n",
    "    if score > best_score:\n",
    "        best_k = k\n",
    "        best_score = score\n",
    "        \n",
    "print(\"Лучшее k =\", best_k)\n",
    "print(\"Лучшая оценка =\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификатор `KNeighborsClassifier` имеет параметр `weights`, который может принимать значения:\n",
    "\n",
    "* `uniform`: единый вес, когда все точки в каждой окрестности имеют одинаковый вес\n",
    "* `distance`: точки взвешиваются, обратно пропорционально расстоянию до них, в этом случае более близкие соседи точки будут иметь большее влияние, чем соседи, находящиеся дальше\n",
    "\n",
    "Выберем лучший классификатор в зависимости от числа соседей `k` и параметра `weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "best_score = 0.0\n",
    "best_k = -1\n",
    "best_method = \"\"\n",
    "for method in [\"uniform\", \"distance\"]:\n",
    "    for k in range(1, 11):\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=k, weights=method)\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        score = knn_clf.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_k = k\n",
    "            best_score = score\n",
    "            best_method = method\n",
    "        \n",
    "print(\"Лучший метод =\", best_method)\n",
    "print(\"Лучшее k =\", best_k)\n",
    "print(\"Лучшая оценка =\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также у классификатора `KNeighborsClassifier` есть параметр `p`, который представляет собой степень в метрике Минковского:\n",
    "\n",
    "$\\rho\\left(\\mathbf{x},\\mathbf{y}\\right) = \\left(\\sum_{i}\\left|x_{i}-y_{i}\\right|^{p}\\right)^{\\frac{1}{p}}$\n",
    "\n",
    "Можно выбрать лучший классификатор в зависимости от числа соседей `k` и параметра `p`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "best_score = 0.0\n",
    "best_k = -1\n",
    "best_p = -1\n",
    "\n",
    "for k in range(1, 11):\n",
    "    for p in range(1, 6):\n",
    "        knn_clf = KNeighborsClassifier(n_neighbors=k, weights=\"distance\", p=p)\n",
    "        knn_clf.fit(X_train, y_train)\n",
    "        score = knn_clf.score(X_test, y_test)\n",
    "        if score > best_score:\n",
    "            best_k = k\n",
    "            best_p = p\n",
    "            best_score = score\n",
    "        \n",
    "print(\"Лучшее k =\", best_k)\n",
    "print(\"Лучшее p =\", best_p)\n",
    "print(\"Лучшая оценка =\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В scikit-learn имеется мощный инструмент для автоматического подбора параметров для моделей машинного обучения `GridSearchCV`. `GridSearchCV` находит наилучшие параметры путем обычного перебора: он создает модель для каждой возможной комбинации параметров. Важно отметить, что такой подход может быть весьма затратным по ресурсам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'weights': ['uniform'], \n",
    "        'n_neighbors': [i for i in range(1, 11)]\n",
    "    },\n",
    "    {\n",
    "        'weights': ['distance'],\n",
    "        'n_neighbors': [i for i in range(1, 11)], \n",
    "        'p': [i for i in range(1, 6)]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(knn_clf, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры лучшего классификатора и значение оценки классификатора находится в следующих свойствах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ускорения нахождения параметров лучшего классификатора можно использовать параллельные вычисления (`n_jobs=-1`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важнейший параметр классификатора – количество соседей – можно оценить также методом \"локтя\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in range(1,60):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,60),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=8)\n",
    "plt.title('Доля ошибок классификации для параметра K', fontsize=20)\n",
    "plt.xlabel('параметр K',fontsize=15)\n",
    "plt.ylabel('Доля ошибок',fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивная байесовская классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Техника наивной байесовской классификации основывается на так называемой теореме Байеса и подходит, в частности, когда размерность входных данных высока. Несмотря на свою простоту наивная байесовская классификация часто превосходит по эффективности более сложные методы классификации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теорема Байеса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм базируется на знаменитой теореме Байеса, в которой фигурируют условные вероятности. \n",
    "\n",
    "Условная вероятность - это вероятность наступления некоторого события при условии, что некоторое другое событие уже произошло. Зная условные вероятности, можно посчитать вероятность события, используя априорную информацию.  \n",
    "\n",
    "Математически теорема Байеса состоит в следующем:\n",
    "\n",
    "$${\\displaystyle P(A\\mid B)={\\frac {P(B\\mid A)\\,P(A)}{P(B)}},}$$\n",
    "\n",
    "где $A$ и $B$ – события и $P(B)\\neq{0}$.\n",
    "\n",
    "$P(A\\mid B)$ – это условная вероятность: правдоподобие наступления события $A$ при условии, что произошло событие $B$.\n",
    "\n",
    "$P(B\\mid A)$ – это также условная вероятность: правдоподобие наступления события $B$ при условии, что произошло событие $A$.\n",
    "\n",
    "$P(A)$ и $P(B)$ – это вероятности наступления $A$ и $B$ независимо друг от друга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему наивный байесовский и почему алгоритм быстр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод называют наивным байесовским, потому что расчет вероятностей для каждого события упрощен, чтобы сделать расчет легко выполнимым. Вместо того, чтобы пытаться вычислить значения каждого значения атрибута, они считаются условно независимыми при заданном целевом значении.\n",
    "\n",
    "Это очень сильное предположение, которое маловероятно в реальных условиях (что признаки не связаны). Тем не менее, этот подход на удивление хорошо работает на различных наборах данных, в т.ч. в тех, в которых это предположение не выполняется.\n",
    "\n",
    "Обучение происходит быстро, потому что необходимо рассчитать только вероятность каждого класса и вероятность каждого класса при различных входных значениях.\n",
    "\n",
    "Вероятности классов - это просто количество записей каждого класса, деленное на общее количество записей. Условные вероятности - это количество появлений каждого значения признака для данного значения класса, деленное на количество записей с этим значением класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера будем рассматривать набор данных о качестве вина \n",
    "(http://archive.ics.uci.edu/ml/datasets/Wine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные из набора и проведем их анализ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datasets.load_wine(as_frame=True).frame\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем диаграммы размаха в разбивке по классам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in df.columns[:-1]:\n",
    "    df.boxplot(c,by='target',figsize=(7,4),fontsize=14)\n",
    "    plt.title(\"{}\\n\".format(c),fontsize=16)\n",
    "    plt.xlabel(\"Класс вина\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из диаграмм размаха следует, что некоторые признаки классифицируют классы вин достаточно хорошо. \n",
    "Например, показателям Alcalinity, Total Phenols или Flavonoids соответствуют диаграммы с хорошо отделимыми медианами, характеризующими классы вин.\n",
    "\n",
    "Ниже визуализация разделения на классы по двум переменным:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['proline'],df['flavanoids'],c=df['target'],edgecolors='k',alpha=0.8,s=100)\n",
    "plt.grid(True)\n",
    "plt.title(\"Диаграмма рассеяния двух признаков,\\nдемонстрирующая корреляцию и разделение классов\",fontsize=15)\n",
    "plt.xlabel(\"proline\",fontsize=15)\n",
    "plt.ylabel(\"Flavanoids\",fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы проверить уровень корреляции между признаками, визуализируем матрицу корреляций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def correlation_matrix(df):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import cm as cm\n",
    "\n",
    "    fig = plt.figure(figsize=(16,12))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    cax = ax1.imshow(df.corr(), interpolation=\"nearest\", cmap=cmap)\n",
    "    ax1.grid(True)\n",
    "    plt.title('Корреляции признаков в наборе данных качества вин\\n',fontsize=15)\n",
    "    labels=df.columns\n",
    "    ax1.set_xticklabels(labels,fontsize=9)\n",
    "    ax1.set_yticklabels(labels,fontsize=9)\n",
    "    fig.colorbar(cax, ticks=[0.1*i for i in range(-11,11)])\n",
    "    plt.show()\n",
    "\n",
    "correlation_matrix(df.drop('target',axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на обучающую и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size=0.3 # тестовая выборка 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1)\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация методом GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть дана переменная класса $y$ и вектор признаков от $x_1$ до $x_n$, тогда теорема Байеса утверждает следующее:\n",
    "\n",
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots x_n \\mid y)} {P(x_1, \\dots, x_n)}$$\n",
    "Используя (наивное) допущение независимости, получаем\n",
    "$$P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n) = P(x_i | y),$$\n",
    "для всех $i$, поэтому \n",
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) \\prod_{i=1}^{n} P(x_i \\mid y)} {P(x_1, \\dots, x_n)}$$\n",
    "\n",
    "Так как вероятность $P(x_1, \\dots, x_n)$ не зависит от $y$, можно воспользоваться следующим правилом классификации:\n",
    "$$P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)$$\n",
    "$$\\Downarrow$$ \n",
    "$$\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y)$$\n",
    "\n",
    "Здесь $P(y)$ – это относительная частота класса $y$ в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределение признаков принимается нормальным:\n",
    "\n",
    "$$ P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}) $$\n",
    "\n",
    "Параметры $\\sigma_y$ и $\\mu_y$ определяются непосредственным расчетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nbc = GaussianNB()\n",
    "nbc.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогнозирование меток классов дает следующий результат (зависящий от разбиения на обучающее и тестовое множества):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nbc.predict(X_test)\n",
    "mislabel = np.sum((y_test!=y_pred))\n",
    "print(\"Количество неправильно классифицированных точек из {} точек тестового множества равно {}\".format(len(y_test),mislabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Можно воспользоваться следующим отчетом о классификации из sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "print(\"Отчет о классификации:\\n\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "При помощи sklearn можно посчитать матрицу ошибок классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = (confusion_matrix(y_test,y_pred))\n",
    "cmdf = pd.DataFrame(cm,index=['Класс 1','Класс 2',' Класс 3'], columns=['Класс 1','Класс 2',' Класс 3'])\n",
    "print(\"Матрица ошибок:\\n\")\n",
    "cmdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При валидации модели используем для оценки качества модели функцию `cross_val_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация по K блокам\n",
    "\n",
    "При кросс-валидации по `k` блокам данные делятся на `k` частей. Модель обучается на `k-1` блоках, при этом один блок откладывается для тестирования. Этот процесс повторяется, чтобы каждый из блоков был использован как тестовый. После завершения процесса получаем  оценку, включающую среднее значение и/или стандартное отклонение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold Cross-Validation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "results_kfold = cross_val_score(nbc, X, y, cv=kfold)\n",
    "print(\"Доля верных ответов (accuracy): %.2f%%\" % (results_kfold.mean()*100.0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стратифицированная кросс-валидация по K блокам\n",
    "\n",
    "Стратифицированный подход представляет собой разновидность кросс-валидации (перекрестной проверки), которая возвращает стратифицированные блоки, т. е. каждый блок содержит примерно такое же соотношение целевых меток, как и полные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-fold Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "results_skfold = cross_val_score(nbc, X, y, cv=skfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results_skfold.mean()*100.0, \n",
    "                                     results_skfold.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация по отдельным объектам (Leave-One-Out)\n",
    "\n",
    "LOOCV — это метод перекрестной валидации, в котором размер блока равен 1, а параметр `k` задается количеством записей в данных. Этот вариант полезен, когда обучающие данные имеют ограниченный размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave One Out Cross-Validation \n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loocv = LeaveOneOut()\n",
    "\n",
    "results_loocv = cross_val_score(nbc, X, y, scoring='recall', cv=loocv)\n",
    "print(\"Полнота: %.2f%%\" % (results_loocv.mean()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Повторяющиеся случайные разбиения на обучающую и тестовую выборки\n",
    "\n",
    "Метод представляет собой гибрид традиционного разделения на обучающую и тестовую выборки и перекрестной проверки k-fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated Random Test-Train Splits\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "kfold_split = ShuffleSplit(n_splits=10, test_size=0.30)\n",
    "\n",
    "results_split = cross_val_score(nbc, X, y, scoring='jaccard_macro', cv=kfold_split)\n",
    "print(\"Коэффициент Жаккара: %.2f%% (%.2f%%)\" % (results_split.mean()*100.0, \n",
    "                                                results_split.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация трехмерных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "xs = iris.data[:,0]\n",
    "ys = iris.data[:,1]\n",
    "zs = iris.data[:,2]\n",
    "ax.scatter( xs, ys, zs, c=iris.target,s=100 )\n",
    "ax.set_xlabel(iris.feature_names[0])\n",
    "ax.set_ylabel(iris.feature_names[1])\n",
    "ax.set_zlabel(iris.feature_names[2])\n",
    "ax.view_init( azim=-120, elev=25 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание на лабораторную работу №4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание (10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для закрепленного за Вами варианта лабораторной работы:\n",
    "\n",
    "1.\tСчитайте из заданного набора данных репозитария UCI значения трех признаков и метки класса. \n",
    "\n",
    "2.\tЕсли среди меток класса имеются пропущенные значения, то удалите записи с пропущенными метками класса. Если в признаках имеются пропущенные значения, то замените пропущенные значения, используя метод, указанный в индивидуальном задании. Если количество различных меток классов превышает 4, то уменьшите количество классов.\n",
    "\n",
    "3. Нормализуйте признаки набора данных методом, указанным в индивидуальном задании.\n",
    "\n",
    "4.\tВизуализируйте набор данных в виде точек трехмерного пространства с координатами, соответствующими трем признакам, отображая точки различных классов разными цветами. Подпишите оси и рисунок, создайте легенду набора данных. \n",
    "\n",
    "5.  Используя алгоритм снижения размерности данных, указанный в индивидуальном задании, уменьшите размерность признакового пространства до двух и визуализируйте набор данных в виде точек на плоскости, отображая точки различных классов разными цветами. Подпишите оси и рисунок, создайте легенду набора данных. \n",
    "\n",
    "6.  Используя разделение набора данных из двух признаков на обучающую и тестовую выборки в соотношении 75% на 25%, проведите классификацию тестовой выборки с помощью метода К ближайших соседей для различных значений К и определите оптимальное значение параметра К с минимальной долей ошибок. \n",
    "\n",
    "7.  Для найденного значения K постройте и выведите на экран отчет о классификации и матрицу ошибок.\n",
    "\n",
    "8. Создайте модели классификации точек набора данных из трех признаков на базе следующих классификаторов:\n",
    "* наивного байесовского классификатора  \n",
    "* классификатора метода К ближайших соседей для значения К, определенного в п. 6.\n",
    "\n",
    "9.  Используя указанный в индивидуальном задании метод валидации модели, проведите для набора данных из трех признаков оценку качества классификаторов из п. 8 относительно показателя, указанного в индивидуальном задании, и выведите на экран среднее значение и дисперсию этого показателя.\n",
    "\n",
    "10. Определите, какой из классификаторов позволяет получить более высокое среднее значение показателя классификации, проведите классификацию точек набора данных этим классификатором и визуализируйте набор данных в виде точек трехмерного пространства с координатами, соответствующими трем признакам, отображая точки различных прогнозируемых классов разными цветами. Подпишите оси и рисунок, создайте легенду набора данных. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
